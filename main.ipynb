{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "109a294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/Projects/Transformer/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Audio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115950f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = load_dataset(\"MLCommons/peoples_speech\", 'clean', split='train')\n",
    "val_ds = load_dataset(\"MLCommons/peoples_speech\", 'clean', split='validation')\n",
    "test_ds = load_dataset(\"MLCommons/peoples_speech\", 'clean', split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4ffc8750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac', 'audio': {'path': '07282016HFUUforum_SLASH_07-28-2016_HFUUforum_DOT_mp3_00000.flac', 'array': array([ 0.14205933,  0.20620728,  0.27151489, ...,  0.00402832,\n",
      "       -0.00628662, -0.01422119]), 'sampling_rate': 16000}, 'duration_ms': 14920, 'text': \"i wanted this to share a few things but i'm going to not share as much as i wanted to share because we are starting late i'd like to get this thing going so we all get home at a decent hour this this election is very important to\"}\n"
     ]
    }
   ],
   "source": [
    "print(next(iter(train_ds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b448c",
   "metadata": {},
   "source": [
    "We observe the structure of the Dataset by printing this first row. \n",
    "\n",
    "The dataset should be already clean, but let's see if we can find something that is out of place.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad34bdba",
   "metadata": {},
   "source": [
    "Next step is now to handle different lengths. In order to do that, we'll:\n",
    "\n",
    "1. pad: If the length of the audio is below 14 seconds\n",
    "\n",
    "2. trucate: if the length of the audio is above 15 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bdf008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import librosa\n",
    "\n",
    "\n",
    "class Transform:\n",
    "  def __init__(\n",
    "      self,\n",
    "      n_mels: int,\n",
    "      fmax: int = 8000,\n",
    "      max_length_in_s: int = 14,\n",
    "      target_sr: int = 1600\n",
    "  ) -> None:\n",
    "    self.max_length_in_s = max_length_in_s\n",
    "    self.target_sr = target_sr\n",
    "    self.n_mels = n_mels\n",
    "    self.fmax = fmax\n",
    "\n",
    "  def __call__(self, sample: dict[str, Any]) -> dict[str, Any]:\n",
    "    sample = self.pad_or_truncate(sample)\n",
    "    sample = self.resample_sr(sample)\n",
    "    sample['spectrogram'] = self.generate_mel_spectrogram(sample)\n",
    "    sample = self.keep_necessary_columns(sample)\n",
    "\n",
    "    return sample\n",
    "\n",
    "  def pad_or_truncate(self, sample: dict[str, Any]) -> dict[str, Any]:\n",
    "    target_freq = 16000\n",
    "    audio = sample['audio']['array']\n",
    "\n",
    "    max_length_per_sample = self.max_length_in_s * target_freq\n",
    "\n",
    "    audio_length = len(audio)\n",
    "\n",
    "    if (audio_length > max_length_per_sample):\n",
    "      audio = audio[:max_length_per_sample]\n",
    "\n",
    "    elif (audio_length < max_length_per_sample):\n",
    "      pad_array = np.zeros((max_length_per_sample - audio_length), dtype=int)\n",
    "      audio = np.pad(audio, pad_array, mode='constant')\n",
    "\n",
    "    sample['audio']['array'] = audio\n",
    "    sample['duration_ms'] = (len(audio) / target_freq) * 1000\n",
    "\n",
    "    return sample\n",
    "\n",
    "  def resample_sr(self, sample: dict[str, Any]) -> dict[str, Any]:\n",
    "    frequency = sample['audio']['sampling_rate']\n",
    "    audio = sample['audio']['array']\n",
    "\n",
    "    resampled = librosa.resample(audio, orig_sr=frequency, target_sr=self.target_sr)\n",
    "\n",
    "    sample['audio']['array'] = resampled\n",
    "    sample['sampling_rate'] = self.target_sr\n",
    "\n",
    "    return sample\n",
    "\n",
    "  def generate_mel_spectrogram(self, sample: dict[str, Any]) -> np.ndarray:\n",
    "    audio = sample['audio']['array']\n",
    "    spectro = librosa.feature.melspectrogram(\n",
    "      y=audio,\n",
    "      sr=self.target_sr,\n",
    "      n_mels=self.n_mels,\n",
    "      fmax=self.fmax\n",
    "    )\n",
    "\n",
    "    db_spectro = librosa.power_to_db(spectro, ref=np.max)\n",
    "\n",
    "    return db_spectro\n",
    "\n",
    "  def keep_necessary_columns(self, sample: dict[str, Any]) -> dict[str, Any]:\n",
    "    formatted_sample: dict[str, Any] = {}\n",
    "\n",
    "    formatted_sample['text'] = sample['text']\n",
    "    formatted_sample['spectrogram'] = sample['spectrogram']\n",
    "\n",
    "    return formatted_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04e29c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import (\n",
    "  SentenceTransformer,\n",
    "  SentenceTransformerTrainingArguments,\n",
    "  SentenceTransformerModelCardData,\n",
    "  SentenceTransformerTrainer\n",
    ")\n",
    "from sentence_transformers.losses import (\n",
    "  MultipleNegativesRankingLoss,\n",
    "  MatryoshkaLoss\n",
    ")\n",
    "from sentence_transformers.evaluation import (\n",
    "  NanoBEIREvaluator\n",
    ")\n",
    "from sentence_transformers.training_args import BatchSamplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5910d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\n",
    "  \"sentence-transformers/clip-ViT-B-16\",\n",
    "  model_card_data=SentenceTransformerModelCardData(\n",
    "    'english',\n",
    "    'MIT',\n",
    "    'One4All'\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a338ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = SentenceTransformerTrainingArguments(\n",
    "  output_dir='./OneClip4All/',\n",
    "  num_train_epochs=1,\n",
    "  per_device_train_batch_size=8,\n",
    "  per_device_eval_batch_size=8,\n",
    "  optim='adamw_torch',\n",
    "  seed=42,\n",
    "  dataloader_num_workers=4,\n",
    "  eval_steps=500,\n",
    "  save_steps=500,\n",
    "  batch_sampler=BatchSamplers.NO_DUPLICATES\n",
    ")\n",
    "\n",
    "info_NCE_loss = MultipleNegativesRankingLoss(\n",
    "  model\n",
    ")\n",
    "matryoska_loss = MatryoshkaLoss(\n",
    "  model=model,\n",
    "  loss=info_NCE_loss,\n",
    "  matryoshka_dims=[512, 256, 128, 64]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "011ed268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 123/123 [00:00<00:00, 77068.93 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 5090/5090 [00:00<00:00, 657155.40 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 30908.65 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 100/100 [00:00<00:00, 47820.13 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 5043/5043 [00:00<00:00, 783025.77 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 33303.99 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 32676.10 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 2953/2953 [00:00<00:00, 196157.55 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 34738.31 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 2518/2518 [00:00<00:00, 1220954.62 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 5035/5035 [00:00<00:00, 622996.07 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 35684.06 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 57/57 [00:00<00:00, 28259.50 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 5046/5046 [00:00<00:00, 1860611.69 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 39045.84 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 70/70 [00:00<00:00, 45037.78 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 2210/2210 [00:00<00:00, 287014.24 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 33710.85 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 244/244 [00:00<00:00, 148234.38 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 3635/3635 [00:00<00:00, 288810.29 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 27464.01 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 34122.23 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 2919/2919 [00:00<00:00, 208096.91 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 50/50 [00:00<00:00, 32650.66 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 56/56 [00:00<00:00, 35969.53 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\n",
      "Generating train split: 100%|██████████| 5745/5745 [00:00<00:00, 168166.74 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 49/49 [00:00<00:00, 31281.72 examples/s]\n",
      "\n",
      "\n",
      "Generating train split: 100%|██████████| 932/932 [00:00<00:00, 590051.52 examples/s]\n",
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "evaluators = []\n",
    "for layer in matryoska_loss.matryoshka_dims:\n",
    "  evaluators.append(\n",
    "    NanoBEIREvaluator()\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78057e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Transform(40)\n",
    "\n",
    "train_ds = train_ds.map(transform)\n",
    "val_ds = val_ds.map(transform)\n",
    "test_ds = test_ds.map(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07561324",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds_low_nmel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainer(\n\u001b[1;32m      2\u001b[0m   model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m   args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m----> 4\u001b[0m   train_dataset\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_ds_low_nmel\u001b[49m,\n\u001b[1;32m      5\u001b[0m   eval_dataset\u001b[38;5;241m=\u001b[39mval_ds_low_nmel,\n\u001b[1;32m      6\u001b[0m   loss\u001b[38;5;241m=\u001b[39mmatryoska_loss,\n\u001b[1;32m      7\u001b[0m   evaluator\u001b[38;5;241m=\u001b[39mevaluators,\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_ds_low_nmel' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = SentenceTransformerTrainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  train_dataset=train_ds,\n",
    "  eval_dataset=val_ds,\n",
    "  loss=matryoska_loss,\n",
    "  evaluator=evaluators,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eec5030",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(\n",
    "  resume_from_checkpoint=True,\n",
    ")\n",
    "\n",
    "model.push_to_hub(\n",
    "  'OneClip4All'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24036602",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05328206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de093750",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
